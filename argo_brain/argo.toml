[data]
# Using project directory for data storage
# Alternative: Use "/home/krela/.argo_data" for home directory storage
root = "/home/krela/llm-argo/.argo_data"
state_dir = "/home/krela/llm-argo/.argo_data/state"
data_raw_path = "/home/krela/llm-argo/.argo_data/data_raw"
models_root = "/mnt/d/llm/models"

[vector_store]
backend = "chroma"
path = "/home/krela/llm-argo/.argo_data/vectordb"

[llm]
base_url = "http://127.0.0.1:8080/v1/chat/completions"
model = "local-llm"
model_name = "qwen3-coder-30b"  # For auto-detection of model-specific parsers and templates

# Best practices from Qwen3-Coder-30B model documentation
# These parameters optimize for balanced creativity and accuracy
temperature = 0.7              # Higher than default for more creative responses
top_p = 0.8                    # Nucleus sampling probability
top_k = 20                     # Limit vocabulary to top 20 tokens
repetition_penalty = 1.05      # Reduce repetition in output
max_tokens = 16384              # Increased from 512 for longer responses

# Tokenizer configuration (optional)
# Set to enable HuggingFace transformers integration
# use_chat_template = 0
# tokenizer_path = "/mnt/d/llm/models/qwen3-coder-30b-unsloth"
